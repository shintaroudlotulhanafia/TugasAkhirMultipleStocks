{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shintaroudlotulhanafia/TugasAkhirMultipleStocks/blob/main/TugasAkhir_Shinta_DRLforMultipleStockTrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning untuk Jual-Beli Saham (Dari Awal): Jual-beli Banyak Saham \n",
        "\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memasangkan Google Drive ke Google Colab**\n",
        "\n",
        "* Kata kunci **from** digunakan untuk mengimpor hanya bagian tertentu dari modul.\n",
        "* Modul merupakan file yang berisi sekumpulan fungsi yang ingin disertakan dalam aplikasi. Untuk membuat modul cukup simpan kode yang Anda inginkan dalam file dengan ekstensi file .py.\n",
        "* **import** melakukan impor seluruh *library*.\n",
        "* **from impor** melakukan impor bagian *library* tertentu.\n",
        "* Mounting adalah proses membuat file dan direktori pada perangkat penyimpanan (seperti google drive) tersedia bagi pengguna untuk dapat diakses.\n",
        "\n"
      ],
      "metadata": {
        "id": "14joHep2krkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSh8pk-r6GJo",
        "outputId": "a4ad4e63-3eba-420d-fac8-1660120e3476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Daftar Isi:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Pendeskrisian Tugas](#0)\n",
        "* [2. Instalasi Paket Python](#1)\n",
        "    * [2.1. Instalasi Paket](#1.1)    \n",
        "    * [2.2. Daftar Paket Python](#1.2)\n",
        "    * [2.3. Impot Paket](#1.3)\n",
        "    * [2.4. Membuat Folder](#1.4)\n",
        "* [3. Mengunduh Data](#2)\n",
        "* [4. Memproses Data](#3)        \n",
        "    * [4.1. IndiKator Teknikal](#3.1)\n",
        "    * [4.2. Melakukan *Feature Engineering*](#3.2)\n",
        "* [5. Membangun Lingkungan Jual-Beli Saham dengan OpenAI Gym-style](#4)  \n",
        "    * [5.1. Pemisahan Data](#4.1)  \n",
        "    * [5.2. Lingkungan untuk Pelatihan *(Training)*](#4.2)    \n",
        "* [6. Melatih Agen DRL](#5)\n",
        "    * [6.1. Agen 1: A2C](#5.1)\n",
        "    * [6.2. Agen 2: PPO](#5.2)\n",
        "    * [6.3. Agen 3: TD3](#5.3)\n",
        "    * [6.4. Agen 4: SAC](#5.4)\n",
        "    * [6.5. Agen 5: DDPG](#5.5)\n",
        "* [7. Melakukan Jual-Beli](#6)\n",
        "    * [7.1. Performa di Dalam Sampel](#6.1)\n",
        "    * [7.2. Performa di Luar Sampel](#6.2)\n",
        "    * [7.3. Hasil Jual-Beli Untuk Setiap Agen Berupa Rangkuman Aksi](#6.3)\n",
        "      * [7.3.1. Agen 1: A2C](#6.3.1)\n",
        "      * [7.3.2. Agen 2: PPO](#6.3.2)\n",
        "      * [7.3.3. Agen 3: TD3](#6.3.3)\n",
        "      * [7.3.4. Agen 4: SAC](#6.3.4)\n",
        "      * [7.3.5. Agen 5: DDPG](#6.3.5)\n",
        "    * [7.4. Hasil Jual-Beli Untuk Setiap Agen Berupa Rangkuman Kondisi dan Aksi](#6.4)\n",
        "      * [7.4.1. Agen 1: A2C](#6.4.1)\n",
        "      * [7.4.2. Agen 2: PPO](#6.4.2)\n",
        "      * [7.4.3. Agen 3: TD3](#6.4.3)\n",
        "      * [7.4.4. Agen 4: SAC](#6.4.4)\n",
        "      * [7.4.5. Agen 5: DDPG](#6.4.5)\n",
        "* [8. Performa Backtesting](#7)  \n",
        "    * [8.1. Status BackTesting](#7.1)\n",
        "    * [8.2. Gambaran BackTesting](#7.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Bagian 1. Pendeskrisian Tugas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "Agen DRL dilatih untuk melakukan jual-beli saham. Tugas tersebut dimodelkan sebagai Markov Decision Process (MDP), dengan fungsi dan tujuannya adalah memaksimalkan pengembalian pengembalian kumulatif *(cummulative return)* yang diharapkan.\n",
        "\n",
        "Definisi state-action-reward pada algoritam DRL kasus kali ini adalah sebagai berikut:\n",
        "\n",
        "* **State s**: Kondisi atau *state* mewakili persepsi agen tentang lingkungan pasar. Sama seperti *trader* manusia yang menganalisis berbagai informasi, agen juga secara pasif mengamati banyak fitur dan belajar dengan cara berinteraksi dengan lingkungan pasar (biasanya dengan menjalankan ulang data historis).\n",
        "\n",
        "* **Tindakan atau *action* a**: Ruang aksi mencakup aksi atau tindakan yang dapat dilakukan agen di setiap status atau kondisi. Misalnya, a {−1, 0, 1}, -1 berarti menjual, 0 berarti menahan, dan 1 berarti membeli. Ketika suatu aksi mengoperasikan beberapa saham, maka, a {−k, ..., 1, 0, 1, ..., k}. Misalnya, \"Beli\n",
        "10 saham TLKM\" atau \"Jual 10 saham TLKM\" maka masing-masing nilai a adalah 10 atau -10.\n",
        "\n",
        "* **Fungsi *reward* atau imbalan r(s, a, s′)**: *Reward* adalah insentif bagi agen untuk mempelajari kebijakan yang lebih baik. Misalnya *reward* dapat berupa perubahan nilai portofolio saat mengambil a pada keadaan s dan tiba pada keadaan baru s', yaitu, r(s, a, s′) = v′-v, v′ mewakili nilai portofolio pada keadaan s′ dan v mewakili nilai portofolio pada keadaan s.\n",
        "\n",
        "* **Environment atau lingkungan jual-beli**: saham penyusun indeks JII dengan tanggal sesuai periode pengujian yang diatur.\n",
        "\n",
        "\n",
        "Data untuk studi kasus ini diperoleh dari Yahoo Finance API. Data berisi harga *Open-High-Low-Close* dan *Volume*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Bagian 2. Instalasi Paket Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Instalasi Paket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* FinRL adalah *open-source framework* pertama yang menunjukkan potensi besar *Reinforcement Learning* keuangan.\n",
        "\n",
        "* FinRL menyediakan berbagai pengaturan untuk melakukan *trading* dengan *Reinforcement Learning* seperti menyediakan ratusan pasar keuangan, algoritma yang canggih, berbagai macam aplikasi keuangan (alokasi portofolio, perdagangan mata uang kripto, *high-frequency trading*), *live trading, cloud deployment,* dll.\n",
        "\n",
        "* Pengaplikasian pustaka FinRL dapat menggunakan alamat berikut, git+https://github.com/AI4Finance-Foundation/FinRL.git. Namun, untuk kemudahan pengaturan nilai sesuai kebutuhan, maka, dilakukanlah *forking* terhadap *repository* tersebut, lalu digunakanlah alamat berikut, git+https://github.com/shintaroudlotulhanafia/FinRL.git\n",
        "\n"
      ],
      "metadata": {
        "id": "nLTicCIBN9CY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPT0ipYE28wL",
        "outputId": "eecacb60-ff9c-49eb-b896-c7af80f7324d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/shintaroudlotulhanafia/FinRL.git\n",
            "  Cloning https://github.com/shintaroudlotulhanafia/FinRL.git to /tmp/pip-req-build-474f_8zt\n",
            "  Running command git clone -q https://github.com/shintaroudlotulhanafia/FinRL.git /tmp/pip-req-build-474f_8zt\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-a9ypqc9r/pyfolio_de77371a6a574ee4a955e1f9664f23e7\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-a9ypqc9r/pyfolio_de77371a6a574ee4a955e1f9664f23e7\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-a9ypqc9r/elegantrl_d6fc3b7f8ce34c718058e25f3a7d667c\n",
            "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-a9ypqc9r/elegantrl_d6fc3b7f8ce34c718058e25f3a7d667c\n",
            "Collecting alpaca_trade_api>=2.1.0\n",
            "  Downloading alpaca_trade_api-2.3.0-py3-none-any.whl (33 kB)\n",
            "Collecting ccxt==1.66.32\n",
            "  Downloading ccxt-1.66.32-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 7.9 MB/s \n",
            "\u001b[?25hCollecting elegantrl\n",
            "  Downloading elegantrl-0.3.3-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 58.6 MB/s \n",
            "\u001b[?25hCollecting exchange_calendars\n",
            "  Downloading exchange_calendars-3.6.3.tar.gz (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.17.3)\n",
            "Collecting jqdatasdk\n",
            "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 52.7 MB/s \n",
            "\u001b[?25hCollecting lz4\n",
            "  Downloading lz4-4.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.3.5)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.6.4)\n",
            "Collecting ray[default]\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.0.2)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting stockstats>=0.4.0\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.37.1)\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.1.2-py3-none-any.whl (13 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (91.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 91.7 MB 46 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (1.12.1+cu113)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (4.6.0.66)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (7.9.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2022.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.7.3)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.11.2)\n",
            "Collecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.8 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (3.8.1)\n",
            "Collecting cryptography>=2.6.1\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting yarl==1.7.2\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2022.6.15)\n",
            "Collecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2.23.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (4.1.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (2.10)\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (2.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.24.3)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.1 MB/s \n",
            "\u001b[?25hCollecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[K     |████████████████████████████████| 299 kB 62.9 MB/s \n",
            "\u001b[?25hCollecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (21.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (1.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.9.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->ccxt==1.66.32->finrl==0.3.5) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.1.0)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (0.12.0)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (0.2.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.5) (1.4.40)\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 192 kB/s \n",
            "\u001b[?25hCollecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (4.12.0)\n",
            "Collecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (3.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (0.10.2)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.16.3-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.5) (3.8.0)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.5\n",
            "  Downloading distlib-0.3.5-py2.py3-none-any.whl (466 kB)\n",
            "\u001b[K     |████████████████████████████████| 466 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.4.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (8.14.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (3.17.3)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (7.1.2)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (4.3.3)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (5.2.1)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil>=5.6.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (5.9.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.5) (1.31.6)\n",
            "Collecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.56.4)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.4.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.8.10)\n",
            "Collecting gym>=0.17\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting protobuf<4.0.0,>=3.15.3\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (2.8.0)\n",
            "Collecting ale-py==0.7.4\n",
            "  Downloading ale_py-0.7.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (7.1.2)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->finrl==0.3.5) (4.64.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (3.2.0)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 53.0 MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.5) (0.0.11)\n",
            "Collecting requests>=2.18.4\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat, gym, AutoROM.accept-rom-license\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.5-py3-none-any.whl size=2737073 sha256=2b39b6f015aadf392da8f4d8c87e86c07a30d137341aa9b30c19a4f603eb2455\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gk_h276n/wheels/63/9d/a4/8d68d3ef0d8a0129024f0f4dcf13c2b01e2ae44c7852ea851d\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.3-py3-none-any.whl size=347429 sha256=35fb04ca3ab635e662b4ed38b31c3190f0df7c3241c5ae955fcf299cf85a8a2d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gk_h276n/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75774 sha256=9ac60771b2f2f7ed2c97b162f13e0532b935e491cf2949929222ea31a119eeca\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gk_h276n/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39780 sha256=b0a57bfd5de97f59d47982b1f9a2145b46b889e283f67085fe832cf75bb177c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
            "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exchange-calendars: filename=exchange_calendars-3.6.3-py3-none-any.whl size=182636 sha256=a6f2f8e61d141daeb746bf3762ec6f3f50a4a13a8f4d79e9cc3c8f6209834e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/a3/19/b4611514d34ffd61d13aef10fefc2dcaf3754145121ceba647\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=82b1d38dc121e88c97991b64f68280071145749fdc8a0dda8f565e8cd7547c9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=953353 sha256=d249eff68aa68c1cbb1ab31fc393ec4be7dcf92fde34b1b6c98b093964173965\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=0c669b8b3ed16fe798b8adce1c6cb661879dbd82dd8793f3439ac2d613a8cff2\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616824 sha256=0e2ae67a6e632345754849f3e5fbc26a385db690b3e51150b0492070f360d2c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=357c08fef49f0c0a7f5f539a3c8d494abf57d36db7a9e4176852aacce6ef1bde\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat gym AutoROM.accept-rom-license\n",
            "Installing collected packages: setuptools, requests, protobuf, yarl, platformdirs, distlib, virtualenv, PyYAML, pycares, psutil, ply, opencensus-context, nvidia-ml-py, msgpack, jedi, gym, grpcio, blessed, AutoROM.accept-rom-license, autorom, websockets, websocket-client, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, prometheus-client, opencensus, nodeenv, mock, identify, gpustat, empyrical, deprecation, cryptography, colorful, cfgv, box2d-py, ale-py, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.8.1\n",
            "    Uninstalling yarl-1.8.1:\n",
            "      Successfully uninstalled yarl-1.8.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.4\n",
            "    Uninstalling msgpack-1.0.4:\n",
            "      Successfully uninstalled msgpack-1.0.4\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 PyYAML-6.0 aiodns-3.0.0 aiohttp-cors-0.7.0 ale-py-0.7.4 alpaca-trade-api-2.3.0 autorom-0.4.2 blessed-1.19.1 box2d-py-2.3.8 ccxt-1.66.32 cfgv-3.3.1 colorful-0.5.4 cryptography-37.0.4 deprecation-2.1.0 distlib-0.3.5 elegantrl-0.3.3 empyrical-0.5.5 exchange-calendars-3.6.3 finrl-0.3.5 gpustat-1.0.0rc1 gputil-1.4.0 grpcio-1.43.0 gym-0.21.0 identify-2.5.3 jedi-0.18.1 jqdatasdk-1.8.10 lz4-4.0.2 mock-4.0.3 msgpack-1.0.3 nodeenv-1.7.0 nvidia-ml-py-11.495.46 opencensus-0.11.0 opencensus-context-0.1.3 platformdirs-2.5.2 ply-3.11 pre-commit-2.20.0 prometheus-client-0.13.1 protobuf-3.19.4 psutil-5.9.1 psycopg2-binary-2.9.3 py-spy-0.3.12 pybullet-3.2.5 pycares-4.2.2 pyfolio-0.9.2+75.g4b901f6 pyluach-2.0.0 pymysql-1.0.2 ray-1.13.0 requests-2.28.1 setuptools-59.5.0 stable-baselines3-1.6.0 stockstats-0.4.1 tensorboardX-2.5.1 thriftpy2-0.4.14 virtualenv-20.16.3 websocket-client-1.3.3 websockets-10.3 wrds-3.1.2 yarl-1.7.2 yfinance-0.1.74\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pkg_resources",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# install finrl library\n",
        "!pip install git+https://github.com/shintaroudlotulhanafia/FinRL.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "<a id='1.2'></a>\n",
        "## 2.2. Daftar Paket Python\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Impot Paket"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Modul Python **pandas** digunakan untuk menganalisis dan memanipulasi data.\n",
        "* Modul Python **numpy** digunakan untuk memproses larik atau array.\n",
        "* Modul Python **matplotlib** digunakan membuat visualisasi data dalam dua dimensi.\n",
        "* Modul Python **matplotlib.pyplot** adalah kumpulan fungsi yang membuat matplotlib berfungsi seperti MATLAB.\n",
        "* Modul Python **Datetime** menyediakan sejumlah fungsi untuk menangani tanggal, waktu, dan interval waktu. Date dan datetime adalah objek dalam Python, bukan string atau timestamps.\n",
        "* **YahooDownloader** menyediakan metode untuk mengambil data saham harian dari API Keuangan Yahoo!\n",
        "* **FeatureEngineer** menyediakan metode untuk preprocessing data harga saham\n",
        "* **data_split** membagi dataset menjadi data pelatihan dan data pengujian berdasarkan tanggal\n",
        "* **StockTradingEnv** Lingkungan perdagangan saham untuk OpenAI gym\n",
        "* **DRLAgent** menyediakan implementasi untuk algoritma DRL\n",
        "* **DataProcessor** memproses data menggunakan prosesor data terpadu\n",
        "* **backtest_stats** menghitung statistik *backtesting*\n",
        "* **backtest_plot** membuat dan menampilkan plot ringkasan laporan *backtesting*.\n",
        "* **get_daily_return** \n",
        "* **get_baseline** mengunduh data berdasarkan suatu indeks pada periode waktu tertentu.\n",
        "* Metode **sys.path.append()** digunakan untuk menambahkan jalur sementara. Dengan demikian, jalur tersebut akan valid untuk sebuah sesi, misalnya.\n",
        "* Python **Itertool** adalah modul yang menyediakan berbagai fungsi yang bekerja pada iterator untuk menghasilkan iterator yang kompleks. Modul ini berfungsi sebagai alat yang cepat dan hemat memori."
      ],
      "metadata": {
        "id": "PrTF0S3hSMaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPqeTTwoh1hn",
        "outputId": "c5e83189-2915-4637-82e7-73ae77b95187"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Membuat Folder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **config** berisi pengaturan tanggal periode training dan trading, indikator, hyperparameter setiap model/agen DRL.\n",
        "* **config_tickers** berisi pengaturan daftar saham yang akan diproses.\n",
        "* **import os** digunakan untuk meng-import modul, merupakan module pada python agar python itu sendiri berinteraksi langsung terhadap sistem operasi.\n",
        "* **check_and_make_directories** digunakan untuk mengecek dan membuat folder.\n"
      ],
      "metadata": {
        "id": "lEXpeGe0GynY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtUc_ofKmpdy"
      },
      "outputs": [],
      "source": [
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Mengunduh Data\n",
        "\n",
        "Yahoo Finance menyediakan data saham, berita keuangan, laporan keuangan, dll, secara gratis.\n",
        "* FinRL *Library* menggunakan kelas **YahooDownloader** di FinRL-Meta untuk mengambil data melalui Yahoo Finance API\n",
        "* Batas Pemanggilan: Menggunakan API Publik (tanpa autentikasi), Pengguna dibatasi hingga 2.000 permintaan per jam per IP (atau hingga total 48.000 permintaan per hari)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "-----\n",
        "kelas YahooDownloader:\n",
        "    Mengambil data saham harian dari\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Atribut\n",
        "    ----------\n",
        "        start_date : str\n",
        "            tanggal mulai data\n",
        "        end_date : str\n",
        "            tanggal akhir data\n",
        "        ticker_list : list\n",
        "            daftar ticker saham (dimodifikasi dari config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penetapan tanggal training dan trading dapat dilakukan dengan mengaturnya pada finrl/config.py atau dengan menetapkannya di sel notebook."
      ],
      "metadata": {
        "id": "QIofwv00IJcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUnY8WEfLq3C"
      },
      "outputs": [],
      "source": [
        "TRAIN_START_DATE = '2009-01-01'\n",
        "TRAIN_END_DATE = '2017-12-31'\n",
        "TRADE_START_DATE = '2018-01-01'\n",
        "TRADE_END_DATE = '2019-09-31'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "3aeac7b0-31be-4db6-abeb-b0b2f480ca5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/multitasking/__init__.py\", line 104, in _run_via_pool\n",
            "    return callee(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/multi.py\", line 190, in _download_one_threaded\n",
            "    timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/multi.py\", line 207, in _download_one\n",
            "    timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/base.py\", line 156, in history\n",
            "    end = int(_time.mktime(_time.strptime(str(end), '%Y-%m-%d')))\n",
            "  File \"/usr/lib/python3.7/_strptime.py\", line 571, in _strptime_time\n",
            "    tt = _strptime(data_string, format)[0]\n",
            "  File \"/usr/lib/python3.7/_strptime.py\", line 544, in _strptime\n",
            "    datetime_date(year, 1, 1).toordinal() + 1\n",
            "ValueError: day is out of range for month\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TRADE_END_DATE,\n",
        "                     ticker_list = config_tickers.JII_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **df.shape** digunakan untuk mendapatkan jumlah baris dan kolom"
      ],
      "metadata": {
        "id": "mzYTM0KcJFth"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV3HrZHLh1hy"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **sort_values()** berfungsi mengurutkan bingkai data dalam urutan Ascending atau Descending dari kolom yang dilewati.\n",
        "* **ignore_index** – Menentukan untuk mereset indeks mulai dari nol. Secara default disetel *false*.\n",
        "* **head()** digunakan untuk mendapatkan n baris pertama."
      ],
      "metadata": {
        "id": "Ugj2Xt76JTSC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hYkeaPiICHS"
      },
      "outputs": [],
      "source": [
        "df.sort_values(['date','tic'],ignore_index=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "<a id='3'></a>\n",
        "# Bagian 4: Memproses Data\n",
        "\n",
        "Periksa data yang hilang dan melakukan *feature engineering* untuk mengubah data menjadi *state*.\n",
        "* **Menambahkan indikator teknis**\n",
        "\n",
        "  Dalam praktik jual-beli, berbagai informasi perlu diperhitungkan, seperti harga historis, kepemilikan saham saat ini, indikator teknis, dll. Indikator teknis yang dapat digunakan antara lain, MACD, RSI, CCI, ADX, Bollinger Bands, dll. \n",
        "* **Menambahkan indeks turbulensi**\n",
        "\n",
        "  Risk-aversion mencerminkan seberapa berani investor melakukan jual-beli saham dengan risiko yang tinggi. Hal ini mempengaruhi strategi trading investor ketika menghadapi tingkat volatilitas pasar yang berbeda. Untuk mengendalikan risiko dalam skenario terburuk, seperti krisis keuangan tahun 1998, FinRL menggunakan indeks turbulensi yang mengukur fluktuasi harga aset yang ekstrem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-----\n",
        "kelas FeatureEngineer:\n",
        "    Menyediakan metode untuk preprocessing data harga saham\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        use_technical_indicator : boolean\n",
        "            menggunakan indikator teknis atau tidak\n",
        "        tech_indicator_list : list\n",
        "            daftar nama indikator teknis (dimodifikasi dari neofinrl_config.py)\n",
        "        use_vix : boolean\n",
        "            menggunakan Volatility Index (VIX) atau tidak\n",
        "        use_turbulence : boolean\n",
        "            menggunakan indeks turbulensi atau tidak\n",
        "        user_defined_feature:boolean\n",
        "            menggunakan fitur yang ditentukan pengguna atau tidak\n",
        "    Methods\n",
        "    -------\n",
        "    preprocess_data()\n",
        "        metode utama untuk melakukan *feature engineering*\n"
      ],
      "metadata": {
        "id": "eOHNe8T2LBOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmKP-1ii3RLS"
      },
      "outputs": [],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = INDICATORS,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **unique()** digunakan untuk menemukan elemen unik dari array. Mengembalikan elemen unik yang diurutkan dari sebuah array.\n",
        "* **tolist()** digunakan untuk mengubah elemen data array menjadi *list*.\n",
        "* **Array** dapat menyimpan elemen hanya dari satu tipe. Sedangkan **list** juga dapat menyimpan elemen dari tipe data yang berbeda.\n",
        "* **list()** digunakan untuk membuat objek *list*. Objek *list* adalah kumpulan yang berurutan dan dapat diubah.\n",
        "* **date_range()** digunakan untuk mendapatkan frekuensi tetap DatetimeIndex. date_range() digunakan untuk membuat rentang tanggal di pandas.\n",
        "* **astype()** digunakan untuk mengubah tipe data dari suatu bentuk *series*.\n",
        "* **max()** mengembalikan item dengan nilai tertinggi, atau item dengan nilai tertinggi dalam *iterable*. Jika nilainya adalah string, maka dilakukan perbandingan abjad.\n",
        "* **min()** mengembalikan item dengan nilai terendah, atau item dengan nilai terendah dalam iterable. Jika nilainya adalah string,  maka dilakukan perbandingan abjad.\n",
        "* **itertools.product()** digunakan untuk mencari produk kartesius dari iterator yang diberikan, outputnya adalah urutan leksikografis. \n",
        "* **Pandas DataFrame** adalah dua dimensi yang dapat berubah ukuran, struktur data tabular yang berpotensi heterogen dengan sumbu berlabel (baris dan kolom).\n",
        "* **merge()** berfungsi untuk memperbarui konten dua DataFrame dengan menggabungkannya bersama-sama, menggunakan metode yang ditentukan.\n",
        "* **isin()** digunakan untuk memfilter data frames. isin() dapat membantu untuk memilih baris dengan memiliki nilai tertentu (atau beberapa nilai tertentu) dalam kolom tertentu.\n",
        "* **fillna()** digunakan untuk mengisi nilai NA/NaN menggunakan metode yang ditentukan. fillna(0) artinya baris NA/NaN diisi dengan nilai misalnya 0.\n",
        "* **nunique()** mengembalikan jumlah nilai unik untuk setiap kolom. Dengan menentukan sumbu kolom ( axis='columns' ), metode nunique() mencari berdasarkan kolom tersebut dan mengembalikan jumlah nilai unik untuk setiap baris.\n",
        "* **info()** berfungsi untuk mencetak informasi tentang DataFrame. Informasi tersebut berisi jumlah kolom, label kolom, tipe data kolom, penggunaan memori, indeks rentang, dan jumlah sel di setiap kolom (nilai bukan nol).\n",
        "* **unique()** digunakan untuk menemukan elemen unik dari array. Mengembalikan elemen unik yang diurutkan dari sebuah array.\n",
        "* **loc** berbasis label, yang berarti baris dan kolom diambil berdasarkan label baris dan kolomnya. **iloc** berbasis posisi integer, maka baris dan kolom dapat diambil dengan menggunakan nilai posisi integernya (posisi integer berbasis 0).\n",
        "* **to_csv()** mengonversi DataFrame menjadi data CSV/comma separated value (nilai yang dipisahkan koma). Kita dapat melewatkan objek file untuk menulis data CSV ke dalam file. Jika tidak, data CSV dikembalikan dalam format string."
      ],
      "metadata": {
        "id": "xTxtW0-pN0aO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kixon2tR3RLT"
      },
      "outputs": [],
      "source": [
        "list_ticker = processed[\"tic\"].unique().tolist()\n",
        "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
        "combination = list(itertools.product(list_date,list_ticker))\n",
        "\n",
        "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
        "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "processed_full = processed_full.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grvhGJJII3Xn"
      },
      "outputs": [],
      "source": [
        "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmPfXQovgDTd"
      },
      "outputs": [],
      "source": [
        "processed_full.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7cFYmuOKoCF"
      },
      "outputs": [],
      "source": [
        "processed_full.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMYtag4AgdA3"
      },
      "outputs": [],
      "source": [
        "print(processed_full['tic'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfKJN9j8vhk6"
      },
      "outputs": [],
      "source": [
        "#Save the dataset by the tic filter\n",
        "\n",
        "for stock in config_tickers.DOW_30_TICKER:\n",
        "  df_temp = processed_full.loc[processed_full['tic'].isin([stock])]\n",
        "  df_temp.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading/DatasetsPerTic/'+ stock +'.csv',index=False)\n",
        "  display(df_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Bagian 5. Membangun Lingkungan Jual-Beli Saham dengan OpenAI Gym-style\n",
        "Proses *training* meliputi mengamati perubahan harga saham, mengambil tindakan dan perhitungan *reward*. Dengan berinteraksi dengan lingkungan pasar, agen pada akhirnya akan memperoleh strategi perdagangan yang dapat memaksimalkan imbalan.\n",
        "\n",
        "*Environment* pasar dibangun  menggunakan OpenAI Gym yang mensimulasikan pasar saham dengan data historis pasar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TOhcryx44bb"
      },
      "source": [
        "<a id='4.1'></a>\n",
        "## 5.1. Memisahkan Data\n",
        "Data dibagi menjadi dua bagian, yaitu bagian pelatihan dan bagian pengujian dengan keterangan sebagai berikut:\n",
        "\n",
        "Periode data pelatihan: 01-01-2009 hingga 30-06-2020\n",
        "\n",
        "Periode data perdagangan: 2020-07-01 hingga 2021-12-31"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **data_split** membagi data menjadi himpunan *train, test,* dan/atau *validation.*\n",
        "* **len()** mengembalikan jumlah item dalam suatu objek. Namun, jika objek adalah string, maka fungsi len() akan mengembalikan jumlah karakter dalam string.\n",
        "* **tail()** digunakan untuk mendapatkan n baris terakhir."
      ],
      "metadata": {
        "id": "mPuF7yjKBY3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0qaVGjLtgbI"
      },
      "outputs": [],
      "source": [
        "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
        "print(len(train))\n",
        "print(len(trade))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p52zNCOhTtLR"
      },
      "outputs": [],
      "source": [
        "train.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9zU9YaTTvFq"
      },
      "outputs": [],
      "source": [
        "trade.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYN573SOHhxG"
      },
      "outputs": [],
      "source": [
        "INDICATORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2zqII8rMIqn"
      },
      "outputs": [],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 10000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}\n",
        "\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64EoqOrQjiVf"
      },
      "source": [
        "<a id='4.2'></a>\n",
        "## 5.2. Lingkungan untuk Pelatihan *(Training)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwSvvPjutpqS"
      },
      "outputs": [],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Bagian 6: Melatih Agen DRL\n",
        "* Algoritma DRL dibangun dengan menggunakan **Stable Baselines 3**. \n",
        "\n",
        "* FinRL mencakup algoritma DRL standar yang disempurnakan, seperti DQN, DDPG, DDPG Multi-Agen, PPO, SAC, A2C, dan TD3. FinRL juga mengizinkan pengguna untuk merancang algoritma DRL sendiri dengan mengadaptasi algoritma DRL yang telah disebutkan."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-----\n",
        "kelas DRLAgent:\n",
        "    Menyediakan implementasi untuk algoritma DRL\n",
        "\n",
        "    Atribut\n",
        "    ----------\n",
        "        env: gym environment class\n",
        "            kelas yang ditentukan pengguna\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "        get_model()\n",
        "            mengatur algoritma DRL\n",
        "        train_model()\n",
        "            melatih algoritma DRL dalam set data latih dan mengeluarkan model yang dilatih\n",
        "        DRL_prediction()\n",
        "            membuat prediksi dalam kumpulan data pengujian dan dapatkan hasil\n"
      ],
      "metadata": {
        "id": "-jcRwntSDfxO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "364PsqckttcQ"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDmqOyF9h1iz"
      },
      "source": [
        "**Agent Training: 5 algorithms (A2C, PPO, TD3, SAC, DDPG)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uijiWgkuh1jB"
      },
      "source": [
        "<a id='5.1'></a>\n",
        "##6.1. Agen 1: A2C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUCnkn-HIbmj"
      },
      "outputs": [],
      "source": [
        "model_a2c = agent.get_model(\"a2c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GVpkWGqH4-D"
      },
      "outputs": [],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                             tb_log_name='a2c',\n",
        "                             total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRiOtrywfAo1"
      },
      "source": [
        "<a id='5.2'></a>\n",
        "##6.2. Agen 2: PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2YadjfnLwgt"
      },
      "outputs": [],
      "source": [
        "model_ddpg = agent.get_model(\"ppo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCDa78rqfO_a"
      },
      "outputs": [],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gDkU-j-fCmZ"
      },
      "source": [
        "<a id='5.3'></a>\n",
        "##6.3. Agen 3: TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5D5PFUhMzSV"
      },
      "outputs": [],
      "source": [
        "model_td3 = agent.get_model(\"td3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt8eIQKYM4G3"
      },
      "outputs": [],
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zpv4S0-fDBv"
      },
      "source": [
        "<a id='5.4'></a>\n",
        "##6.4. Agen 4: SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSAHhV4Xc-bh"
      },
      "outputs": [],
      "source": [
        "model_sac = agent.get_model(\"sac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSRxNYAxdKpU"
      },
      "outputs": [],
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=30000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr49PotrfG01"
      },
      "source": [
        "<a id='5.5'></a>\n",
        "##6.5. Agen 5: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwOhVjqRkCdM"
      },
      "outputs": [],
      "source": [
        "model_ddpg = agent.get_model(\"ddpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8RSdKCckJyH"
      },
      "outputs": [],
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6'></a>\n",
        "# Bagian 7: Melakukan Jual-Beli"
      ],
      "metadata": {
        "id": "EminKd_re78H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2wZgkQXh1jE"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1. Performa di Dalam Sampel\n",
        "\n",
        "Asumsikan modal awal adalah Rp10.000.000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEv5KGC8h1jE"
      },
      "source": [
        "Pengaturan ambang turbulensi *(turbulence threshold)*\n",
        "\n",
        "Atur ambang turbulensi menjadi lebih besar dari maksimum dalam data turbulensi sampel. Jika indeks turbulensi saat ini lebih besar dari ambang batas, maka dapat diasumsikan bahwa pasar pada periode tersebut sedang bergejolak"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **drop_duplicates()** menghapus baris duplikat."
      ],
      "metadata": {
        "id": "rvpNyg4kFWGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efwBi84ch1jE"
      },
      "outputs": [],
      "source": [
        "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
        "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHZMBpSqh1jG"
      },
      "outputs": [],
      "source": [
        "insample_risk_indicator.vix.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDkszkMloRWT"
      },
      "outputs": [],
      "source": [
        "insample_risk_indicator.vix.quantile(0.996)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL7hs7svnNWT"
      },
      "outputs": [],
      "source": [
        "insample_risk_indicator.turbulence.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N78hfHckoqJ9"
      },
      "outputs": [],
      "source": [
        "insample_risk_indicator.turbulence.quantile(0.996)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5mmgQF_h1jQ"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "##7.2. Performa di Luar Sampel\n",
        "\n",
        "FinRL dapat diatur dengan cara melakukan pelatihan ulang secara berkala, misalnya, pelatihan ulang setiap tiga bulan, bulanan, atau mingguan. \n",
        "\n",
        "Pada notebook ini, *hyperparameter* hanya diatur satu kali dengan menggunakan data sampel selama periode yang telah ditetapkan. Sehingga, terjadi beberapa peluruhan alfa seiring dengan perpanjangan tanggal perdagangan.\n",
        "\n",
        "Banyak *hyperparameter* – mis. learning rate, mempengaruhi proses pembelajaran dan biasanya ditentukan dengan menguji beberapa variasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIqoV0GSI52v"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70, risk_indicator_col='vix', **env_kwargs)\n",
        "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_XNgGsBMeVw"
      },
      "outputs": [],
      "source": [
        "trade.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy2AGzVLny4p"
      },
      "source": [
        "<a id='6.3'></a>\n",
        "##7.3. Hasil Jual-Beli Untuk Setiap Agen Berupa Rangkuman Aksi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvRo8FHD4E91"
      },
      "source": [
        "<a id='6.3.1'></a>\n",
        "###7.3.1. Agen 1: A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmQiDwHx5ZwL"
      },
      "outputs": [],
      "source": [
        "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
        "    model=trained_a2c, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZM67XNS5jv4"
      },
      "outputs": [],
      "source": [
        "df_actions_and_account_value_a2c = pd.merge(df_actions_a2c, df_account_value_a2c, on='date', how='outer')\n",
        "\n",
        "#adding new column\n",
        "df_actions_and_account_value_a2c['total_shares'] = \"\"\n",
        "\n",
        "#selecting column of actions in every tics\n",
        "action_columns_a2c = df_actions_and_account_value_a2c.iloc[:,1:30]\n",
        "\n",
        "# sum each row\n",
        "df_actions_and_account_value_a2c['total_shares'] = action_columns_a2c.sum(axis = 1)\n",
        "\n",
        "#cumulative sum of total_share\n",
        "df_actions_and_account_value_a2c['total_shares'] = df_actions_and_account_value_a2c['total_shares'].cumsum(skipna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng2IuHlc8wHx"
      },
      "outputs": [],
      "source": [
        "#define function to swap columns\n",
        "def swap_columns(df, col1, col2):\n",
        "    col_list = list(df.columns)\n",
        "    x, y = col_list.index(col1), col_list.index(col2)\n",
        "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
        "    df = df[col_list]\n",
        "    return df\n",
        "\n",
        "#swap points and rebounds columns\n",
        "df_actions_and_account_value_a2c = swap_columns(df_actions_and_account_value_a2c, 'account_value', 'total_shares')\n",
        "\n",
        "#view updated DataFrame\n",
        "display(df_actions_and_account_value_a2c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNJWKB9X9P2-"
      },
      "outputs": [],
      "source": [
        "#df_actions_and_account_value_a2c.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading/ActionsPerModel/df_actions_and_account_value_a2c(2).csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZxyWPaz4YyF"
      },
      "source": [
        "<a id='6.3.2'></a>\n",
        "###7.3.2. Agen 2: PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vQvrfNL4Jby"
      },
      "outputs": [],
      "source": [
        "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
        "    model=trained_ppo, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6FYXbFN-DJm"
      },
      "outputs": [],
      "source": [
        "df_actions_and_account_value_ppo = pd.merge(df_actions_ppo, df_account_value_ppo, on='date', how='outer')\n",
        "\n",
        "#adding new column\n",
        "df_actions_and_account_value_ppo['total_shares'] = \"\"\n",
        "\n",
        "#selecting column of actions in every tics\n",
        "action_columns_ppo = df_actions_and_account_value_ppo.iloc[:,1:30]\n",
        "\n",
        "# sum each row\n",
        "df_actions_and_account_value_ppo['total_shares'] = action_columns_ppo.sum(axis = 1)\n",
        "\n",
        "#cumulative sum of total_share\n",
        "df_actions_and_account_value_ppo['total_shares'] = df_actions_and_account_value_ppo['total_shares'].cumsum(skipna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7qd5Ker-Iwi"
      },
      "outputs": [],
      "source": [
        "#swap points and rebounds columns\n",
        "df_actions_and_account_value_ppo = swap_columns(df_actions_and_account_value_ppo, 'account_value', 'total_shares')\n",
        "\n",
        "#view updated DataFrame\n",
        "display(df_actions_and_account_value_ppo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z72J_TnL_UKg"
      },
      "outputs": [],
      "source": [
        "#df_actions_and_account_value_ppo.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading/ActionsPerModel/df_actions_and_account_value_ppo(2).csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_csVWrC4ec1"
      },
      "source": [
        "<a id='6.3.3'></a>\n",
        "###7.3.3. Agen 3: TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZgXNA4x4MYN"
      },
      "outputs": [],
      "source": [
        "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
        "    model=trained_td3, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFGaIiKA-b3V"
      },
      "outputs": [],
      "source": [
        "df_actions_and_account_value_td3 = pd.merge(df_actions_td3, df_account_value_td3, on='date', how='outer')\n",
        "\n",
        "#adding new column\n",
        "df_actions_and_account_value_td3['total_shares'] = \"\"\n",
        "\n",
        "#selecting column of actions in every tics\n",
        "action_columns_td3 = df_actions_and_account_value_td3.iloc[:,1:30]\n",
        "\n",
        "# sum each row\n",
        "df_actions_and_account_value_td3['total_shares'] = action_columns_td3.sum(axis = 1)\n",
        "\n",
        "#cumulative sum of total_share\n",
        "df_actions_and_account_value_td3['total_shares'] = df_actions_and_account_value_td3['total_shares'].cumsum(skipna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlufD8vN-lSY"
      },
      "outputs": [],
      "source": [
        "#swap points and rebounds columns\n",
        "df_actions_and_account_value_td3 = swap_columns(df_actions_and_account_value_td3, 'account_value', 'total_shares')\n",
        "\n",
        "#view updated DataFrame\n",
        "display(df_actions_and_account_value_td3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSEWqOuI_XU2"
      },
      "outputs": [],
      "source": [
        "#df_actions_and_account_value_td3.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading/ActionsPerModel/df_actions_and_account_value_td3(2).csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hn1IzaV4kjF"
      },
      "source": [
        "<a id='6.3.4'></a>\n",
        "###7.3.4. Agen 4: SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VeruS6I4mBN"
      },
      "outputs": [],
      "source": [
        "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
        "    model=trained_sac, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MsKz4-W-vp2"
      },
      "outputs": [],
      "source": [
        "df_actions_and_account_value_sac = pd.merge(df_actions_sac, df_account_value_sac, on='date', how='outer')\n",
        "\n",
        "#adding new column\n",
        "df_actions_and_account_value_sac['total_shares'] = \"\"\n",
        "\n",
        "#selecting column of actions in every tics\n",
        "action_columns_sac = df_actions_and_account_value_sac.iloc[:,1:30]\n",
        "\n",
        "# sum each row\n",
        "df_actions_and_account_value_sac['total_shares'] = action_columns_sac.sum(axis = 1)\n",
        "\n",
        "#cumulative sum of total_share\n",
        "df_actions_and_account_value_sac['total_shares'] = df_actions_and_account_value_sac['total_shares'].cumsum(skipna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfOIW7xo-xCU"
      },
      "outputs": [],
      "source": [
        "#swap points and rebounds columns\n",
        "df_actions_and_account_value_sac = swap_columns(df_actions_and_account_value_sac, 'account_value', 'total_shares')\n",
        "\n",
        "#view updated DataFrame\n",
        "display(df_actions_and_account_value_sac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvqGrK-U_Z59"
      },
      "outputs": [],
      "source": [
        "#df_actions_and_account_value_sac.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading/ActionsPerModel/df_actions_and_account_value_sac(2).csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-_Me-lZ4zfF"
      },
      "source": [
        "<a id='6.3.5'></a>\n",
        "###7.3.5. Agen 5: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWOOVpmy4ohw"
      },
      "outputs": [],
      "source": [
        "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
        "    model=trained_ddpg, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MksUaJ2_Alj"
      },
      "outputs": [],
      "source": [
        "df_actions_and_account_value_ddpg = pd.merge(df_actions_ddpg, df_account_value_ddpg, on='date', how='outer')\n",
        "\n",
        "#adding new column\n",
        "df_actions_and_account_value_ddpg['total_shares'] = \"\"\n",
        "\n",
        "#selecting column of actions in every tics\n",
        "action_columns_ddpg = df_actions_and_account_value_ddpg.iloc[:,1:30]\n",
        "\n",
        "# sum each row\n",
        "df_actions_and_account_value_ddpg['total_shares'] = action_columns_ddpg.sum(axis = 1)\n",
        "\n",
        "#cumulative sum of total_share\n",
        "df_actions_and_account_value_ddpg['total_shares'] = df_actions_and_account_value_ddpg['total_shares'].cumsum(skipna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK6u1ewm_EBx"
      },
      "outputs": [],
      "source": [
        "#swap points and rebounds columns\n",
        "df_actions_and_account_value_ddpg = swap_columns(df_actions_and_account_value_ddpg, 'account_value', 'total_shares')\n",
        "\n",
        "#view updated DataFrame\n",
        "display(df_actions_and_account_value_ddpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTsqoizK_dka"
      },
      "outputs": [],
      "source": [
        "#df_actions_and_account_value_ddpg.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading/ActionsPerModel/df_actions_and_account_value_ddpg(2).csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6.4'></a>\n",
        "##7.4. Hasil Jual-Beli Untuk Setiap Agen Berupa Rangkuman Kondisi dan Aksi"
      ],
      "metadata": {
        "id": "9VXRW6t6gcQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_of_tic = processed_full['tic'].unique()"
      ],
      "metadata": {
        "id": "lHA7DpXnn9NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6.4.1'></a>\n",
        "###7.4.1. Agen 1: A2C"
      ],
      "metadata": {
        "id": "8Vnd8oT7grqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop some columns\n",
        "df_actions_and_account_value_a2c = df_actions_and_account_value_a2c.drop(['date', 'total_shares', 'account_value'], axis=1)\n",
        "\n",
        "# create empty list\n",
        "dataframes_list = []\n",
        "\n",
        "#read the dataset of each stock, then put them on dataframes_list\n",
        "for stock in processed_full['tic'].unique():\n",
        "  df_temp = processed_full.loc[processed_full['tic'].isin([stock])]\n",
        "  mask = (df_temp['date'] >= TRADE_START_DATE) & (df_temp['date'] <= TRADE_END_DATE)\n",
        "  df_temp = df_temp.loc[mask]\n",
        "  dataframes_list.append(df_temp)\n",
        "  #display(df_temp)\n",
        "\n",
        "#separate each column of trading dataframe action, then put them on action_per_tic_list\n",
        "action_per_tic_list = []\n",
        "for i in df_actions_and_account_value_a2c:\n",
        "    df_temp = df_actions_and_account_value_a2c[[i]]\n",
        "    action_per_tic_list.append(df_temp)\n",
        "    #display(df_temp)\n",
        "\n",
        "# merging each dataframes_list members and each action_per_tic_list members\n",
        "j=0\n",
        "for i in dataframes_list:\n",
        "  if j<21:\n",
        "   i['action'] = action_per_tic_list[j].iloc[:, 0].values.tolist()\n",
        "   display(i)\n",
        "   #i.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading(2)/HasilPengujian/TabelKondisiAksi/3Indikator/Running1/A2C/df_actions_and_account_value_a2c_'+name_of_tic[j]+'.csv',index=False)\n",
        "   j+=1"
      ],
      "metadata": {
        "id": "NxRGopnRmLF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6.4.2'></a>\n",
        "###7.4.2.Agen 2: PPO"
      ],
      "metadata": {
        "id": "1Rk3R_asguO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop some columns\n",
        "df_actions_and_account_value_ppo = df_actions_and_account_value_ppo.drop(['date', 'total_shares', 'account_value'], axis=1)\n",
        "\n",
        "# create empty list\n",
        "dataframes_list = []\n",
        "\n",
        "#read the dataset of each stock, then put them on dataframes_list\n",
        "for stock in processed_full['tic'].unique():\n",
        "  df_temp = processed_full.loc[processed_full['tic'].isin([stock])]\n",
        "  mask = (df_temp['date'] >= TRADE_START_DATE) & (df_temp['date'] <= TRADE_END_DATE)\n",
        "  df_temp = df_temp.loc[mask]\n",
        "  dataframes_list.append(df_temp)\n",
        "  #display(df_temp)\n",
        "\n",
        "#separate each column of trading dataframe action, then put them on action_per_tic_list\n",
        "action_per_tic_list = []\n",
        "for i in df_actions_and_account_value_ppo:\n",
        "    df_temp = df_actions_and_account_value_ppo[[i]]\n",
        "    action_per_tic_list.append(df_temp)\n",
        "    #display(df_temp)\n",
        "\n",
        "# merging each dataframes_list members and each action_per_tic_list members\n",
        "j=0\n",
        "for i in dataframes_list:\n",
        "  if j<21:\n",
        "   i['action'] = action_per_tic_list[j].iloc[:, 0].values.tolist()\n",
        "   display(i)\n",
        "   j+=1\n",
        "   #i.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading(2)/HasilPengujian/TabelKondisiAksi/3Indikator/Running1/PPO/df_actions_and_account_value_ppo_'+name_of_tic[j]+'.csv',index=False)"
      ],
      "metadata": {
        "id": "lyGOfoZVmL3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6.4.3'></a>\n",
        "###7.4.3. Agen 3: TD3"
      ],
      "metadata": {
        "id": "NBWqZbNFgxF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop some columns\n",
        "df_actions_and_account_value_td3 = df_actions_and_account_value_td3.drop(['date', 'total_shares', 'account_value'], axis=1)\n",
        "\n",
        "# create empty list\n",
        "dataframes_list = []\n",
        "\n",
        "#read the dataset of each stock, then put them on dataframes_list\n",
        "for stock in processed_full['tic'].unique():\n",
        "  df_temp = processed_full.loc[processed_full['tic'].isin([stock])]\n",
        "  mask = (df_temp['date'] >= TRADE_START_DATE) & (df_temp['date'] <= TRADE_END_DATE)\n",
        "  df_temp = df_temp.loc[mask]\n",
        "  dataframes_list.append(df_temp)\n",
        "  #display(df_temp)\n",
        "\n",
        "#separate each column of trading dataframe action, then put them on action_per_tic_list\n",
        "action_per_tic_list = []\n",
        "for i in df_actions_and_account_value_td3:\n",
        "    df_temp = df_actions_and_account_value_td3[[i]]\n",
        "    action_per_tic_list.append(df_temp)\n",
        "    #display(df_temp)\n",
        "\n",
        "# merging each dataframes_list members and each action_per_tic_list members\n",
        "j=0\n",
        "for i in dataframes_list:\n",
        "  if j<21:\n",
        "   i['action'] = action_per_tic_list[j].iloc[:, 0].values.tolist()\n",
        "   display(i)\n",
        "   j+=1\n",
        "   #i.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading(2)/HasilPengujian/TabelKondisiAksi/3Indikator/Running1/TD3/df_actions_and_account_value_td3_'+name_of_tic[j]+'.csv',index=False)"
      ],
      "metadata": {
        "id": "VBIbR8PdmMYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6.4.4'></a>\n",
        "###7.4.4. Agen 4: SAC"
      ],
      "metadata": {
        "id": "OuY3SAbvg0Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop some columns\n",
        "df_actions_and_account_value_sac = df_actions_and_account_value_sac.drop(['date', 'total_shares', 'account_value'], axis=1)\n",
        "\n",
        "# create empty list\n",
        "dataframes_list = []\n",
        "\n",
        "#read the dataset of each stock, then put them on dataframes_list\n",
        "for stock in processed_full['tic'].unique():\n",
        "  df_temp = processed_full.loc[processed_full['tic'].isin([stock])]\n",
        "  mask = (df_temp['date'] >= TRADE_START_DATE) & (df_temp['date'] <= TRADE_END_DATE)\n",
        "  df_temp = df_temp.loc[mask]\n",
        "  dataframes_list.append(df_temp)\n",
        "  #display(df_temp)\n",
        "\n",
        "#separate each column of trading dataframe action, then put them on action_per_tic_list\n",
        "action_per_tic_list = []\n",
        "for i in df_actions_and_account_value_sac:\n",
        "    df_temp = df_actions_and_account_value_sac[[i]]\n",
        "    action_per_tic_list.append(df_temp)\n",
        "    #display(df_temp)\n",
        "\n",
        "# merging each dataframes_list members and each action_per_tic_list members\n",
        "j=0\n",
        "for i in dataframes_list:\n",
        "  if j<21:\n",
        "   i['action'] = action_per_tic_list[j].iloc[:, 0].values.tolist()\n",
        "   display(i)\n",
        "   j+=1\n",
        "   #i.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading(2)/HasilPengujian/TabelKondisiAksi/3Indikator/Running1/SAC/df_actions_and_account_value_sac_'+name_of_tic[j]+'.csv',index=False)"
      ],
      "metadata": {
        "id": "hREohH85mM9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='6.4.5'></a>\n",
        "###7.4.5. Agen 5: DDPG"
      ],
      "metadata": {
        "id": "iRw8ycMzg2ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop some columns\n",
        "df_actions_and_account_value_ddpg = df_actions_and_account_value_ddpg.drop(['date', 'total_shares', 'account_value'], axis=1)\n",
        "\n",
        "# create empty list\n",
        "dataframes_list = []\n",
        "\n",
        "#read the dataset of each stock, then put them on dataframes_list\n",
        "for stock in processed_full['tic'].unique():\n",
        "  df_temp = processed_full.loc[processed_full['tic'].isin([stock])]\n",
        "  mask = (df_temp['date'] >= TRADE_START_DATE) & (df_temp['date'] <= TRADE_END_DATE)\n",
        "  df_temp = df_temp.loc[mask]\n",
        "  dataframes_list.append(df_temp)\n",
        "  #display(df_temp)\n",
        "\n",
        "#separate each column of trading dataframe action, then put them on action_per_tic_list\n",
        "action_per_tic_list = []\n",
        "for i in df_actions_and_account_value_ddpg:\n",
        "    df_temp = df_actions_and_account_value_ddpg[[i]]\n",
        "    action_per_tic_list.append(df_temp)\n",
        "    #display(df_temp)\n",
        "\n",
        "# merging each dataframes_list members and each action_per_tic_list members\n",
        "j=0\n",
        "for i in dataframes_list:\n",
        "  if j<21:\n",
        "   i['action'] = action_per_tic_list[j].iloc[:, 0].values.tolist()\n",
        "   display(i)\n",
        "   j+=1\n",
        "   #i.to_csv('/content/drive/MyDrive/DRLforMultipleStocksTrading(2)/HasilPengujian/TabelKondisiAksi/3Indikator/Running1/DDPG/df_actions_and_account_value_ddpg_'+name_of_tic[j]+'.csv',index=False)"
      ],
      "metadata": {
        "id": "36zWVxVkmNiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='7'></a>\n",
        "# Bagian 8: Performa Backtesting\n",
        "Backtesting memiliki peran kunci dalam mengevaluasi kinerja strategi perdagangan. Alat backtesting otomatis lebih disukai karena dapat meminimalisir kesalahan manusia. Backtesting dapat dilakukan dengan menggunakan paket Quantopian pyfolio untuk menguji strategi perdagangan pada notebook ini. Backtesting tersebut mudah digunakan dan terdiri dari berbagai plot yang memberikan gambaran komprehensif tentang kinerja strategi perdagangan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='7.1'></a>\n",
        "## 8.1 Status BackTesting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzkr9yv-AdV_"
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results of A2C Model===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_a2c)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_a2c_\"+now+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFewBtYXHXCr"
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results of PPO Model===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_ppo)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_ppo_\"+now+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSl4segGHW0Y"
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results of TD3 Model===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_td3)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_td3_\"+now+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2X2EzsFHWjq"
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results of SAC Model===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_sac)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_sac_\"+now+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAnbfJd0HWPf"
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results of DDPG Model===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_ddpg)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_ddpg_\"+now+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkV-LB66iwhD"
      },
      "outputs": [],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^JKII\", \n",
        "        start = df_account_value_a2c.loc[0,'date'],\n",
        "        end = df_account_value_a2c.loc[len(df_account_value_a2c)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg1kvfemrrQH"
      },
      "outputs": [],
      "source": [
        "df_account_value_a2c.loc[0,'date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt1bzL5OrsTa"
      },
      "outputs": [],
      "source": [
        "df_account_value_a2c.loc[len(df_account_value_a2c)-1,'date']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='7.2'></a>\n",
        "## 8.2 Gambaran BackTesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKRGftSS7pNM"
      },
      "outputs": [],
      "source": [
        "print(\"==============A2C Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "# JII: ^JKII\n",
        "backtest_plot(df_account_value_a2c, \n",
        "             baseline_ticker = '^JKII', \n",
        "             baseline_start = df_account_value_a2c.loc[0,'date'],\n",
        "             baseline_end = df_account_value_a2c.loc[len(df_account_value_a2c)-1,'date'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============PPO Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "# JII: ^JKII\n",
        "backtest_plot(df_account_value_ppo, \n",
        "             baseline_ticker = '^JKII', \n",
        "             baseline_start = df_account_value_ppo.loc[0,'date'],\n",
        "             baseline_end = df_account_value_ppo.loc[len(df_account_value_ppo)-1,'date'])"
      ],
      "metadata": {
        "id": "1cetr-EupwdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============TD3 Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "# JII: ^JKII\n",
        "backtest_plot(df_account_value_td3, \n",
        "             baseline_ticker = '^JKII', \n",
        "             baseline_start = df_account_value_td3.loc[0,'date'],\n",
        "             baseline_end = df_account_value_td3.loc[len(df_account_value_td3)-1,'date'])"
      ],
      "metadata": {
        "id": "K8x8rnJLpyHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============SAC Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "# JII: ^JKII\n",
        "backtest_plot(df_account_value_sac, \n",
        "             baseline_ticker = '^JKII', \n",
        "             baseline_start = df_account_value_sac.loc[0,'date'],\n",
        "             baseline_end = df_account_value_sac.loc[len(df_account_value_sac)-1,'date'])"
      ],
      "metadata": {
        "id": "fK3iuN5vpyu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============DDPG Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "# JII: ^JKII\n",
        "backtest_plot(df_account_value_ddpg, \n",
        "             baseline_ticker = '^JKII', \n",
        "             baseline_start = df_account_value_ddpg.loc[0,'date'],\n",
        "             baseline_end = df_account_value_ddpg.loc[len(df_account_value_ddpg)-1,'date'])"
      ],
      "metadata": {
        "id": "gaBjQrTppzRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TugasAkhir_Shinta_DRLforMultipleStockTrading.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}